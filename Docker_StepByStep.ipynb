{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d8d3554-b60b-4c01-93d2-bddaa0abdd55",
   "metadata": {},
   "source": [
    "# üöÄ Tutoriel : Lancer Jupyter Notebook avec PySpark dans Docker\n",
    "\n",
    "Suivez ces √©tapes pour installer et ex√©cuter un Jupyter Notebook avec PySpark via Docker.  \n",
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£ Installer Docker\n",
    "\n",
    "üí° **Astuce** : Docker permet de lancer des applications dans des conteneurs isol√©s.\n",
    "\n",
    "- T√©l√©chargez et installez Docker : [https://www.docker.com/get-started](https://www.docker.com/get-started)  \n",
    "- V√©rifiez l‚Äôinstallation :\n",
    "\n",
    "```bash\n",
    "docker --version\n",
    "\n",
    "```\n",
    "‚úÖ Docker install√© correctement si une version s‚Äôaffiche."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ce0aa8-1f89-49e9-88f0-264b7f42989c",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ T√©l√©charger l‚Äôimage Docker Jupyter Spark\n",
    "\n",
    "üîΩ T√©l√©chargez l‚Äôimage officielle avec PySpark 3.5 :\n",
    "```bash\n",
    "docker pull jupyter/all-spark-notebook:spark-3.5.0\n",
    "\n",
    "‚ö†Ô∏è Cette √©tape peut prendre quelques minutes selon votre connexion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9baccf6d-21f7-47c5-ab76-43c452a31f7a",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Cr√©er un r√©pertoire pour vos donn√©es Spark\n",
    "\n",
    "üìÇ Cr√©ez un dossier sparkdata pour stocker vos fichiers CSV :\n",
    "```bash\n",
    "mkdir -p /Users/datasciencefm/workspace/sparkdata\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d949e0d-49ca-4602-95f2-79a3951ef7b4",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Lancer le conteneur Docker\n",
    "\n",
    "üèÉ‚Äç‚ôÇÔ∏è Ex√©cutez la commande suivante pour lancer Jupyter Lab dans Docker :\n",
    "\n",
    "``` bash\n",
    "docker run -d -P --name notebook -v /Users/datasciencefm/workspace/sparkdata:/sparkdata jupyter/all-spark-notebook:spark-3.5.0\n",
    "\n",
    "-d : lance le conteneur en arri√®re-plan\n",
    "\n",
    "-P : publie automatiquement les ports\n",
    "\n",
    "-v : monte votre dossier sparkdata dans le conteneur\n",
    "```\r",
    "‚ö†Ô∏è Remplacez /Users/datasciencefm/workspace/sparkdata par le chemin de votre propre dossier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419c4a0e-eb12-4444-b370-6aea51fb263c",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ R√©cup√©rer le port expos√©\n",
    "\n",
    "üîç V√©rifiez sur quel port le notebook est accessible :\n",
    "``` bash\n",
    "docker port notebook 8888\n",
    "```\n",
    "Exemple de sortie : \n",
    "``` bash\n",
    "0.0.0.0:55002"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394f3513-af56-4b3a-86f1-8ea10636a667",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ R√©cup√©rer le token du Notebook\n",
    "\n",
    "üîë Pour acc√©der √† Jupyter Lab, r√©cup√©rez le token dans les logs :\n",
    "\n",
    "``` bash\n",
    "docker logs --tail 3 notebook\n",
    "\n",
    "```\n",
    "Vous verrez un lien comme :\n",
    "``` bash\n",
    "http://127.0.0.1:8888/lab?token=YOUR_TOKEN_HERE\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dbbf82-eacc-48a4-a32a-d1b9706c2da9",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Acc√©der √† Jupyter Notebook\n",
    "\n",
    "üåê Ouvrez le lien dans votre navigateur en rempla√ßant PORT et YOUR_TOKEN par vos valeurs :\n",
    "``` bash\n",
    "http://127.0.0.1:PORT/lab?token=YOUR_TOKEN\n",
    "```\n",
    "\n",
    "Vous √™tes maintenant dans l‚Äôinterface Jupyter Lab pr√™te pour PySpark !\n",
    "\n",
    "Vous pouvez cr√©er un notebook et commencer √† coder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e3831a-ff77-4780-aaac-9070cc2b5c31",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Plonger dans PySpark\n",
    "\n",
    "üíª Exemple pour tester PySpark dans un notebook :\n",
    "``` bash \n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Test\").getOrCreate()\n",
    "df = spark.createDataFrame([(1, \"Alice\"), (2, \"Bob\")], [\"id\", \"name\"])\n",
    "df.show()\n",
    "\n",
    "```\n",
    "‚úÖ Vous avez maintenant PySpark fonctionnel dans Jupyter !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7f02d088-8ab4-4b38-aed8-50153c9ad879",
   "metadata": {},
   "source": [
    "## Voil√†√† !\n",
    "![Voil√†√† !](notebook.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfaea75-a8b4-4cfd-9cd4-fa00e8beea0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
